{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/Users/diegofiori/Desktop/epfl/master_thesis/master_thesis/')\n",
    "from utils import read_pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/diegofiori/Desktop/epfl/master_thesis/results/'\n",
    "sim_code = 'qs_no_comp'\n",
    "density = read_pickle(path+f'physical_features_end_{sim_code}.pickle')\n",
    "slices = read_pickle(path+f'slices_top_features_end_{sim_code}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = np.concatenate(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268,)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7680, 11134)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slices = [slices[:, i:i+80] for i in range(0, slices.shape[1], 80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slices = np.concatenate([np.expand_dims(slice_, axis=1) for slice_ in slices], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = slices[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "arrays = []\n",
    "for i in range(slices.shape[0]):\n",
    "    for k in range(slices.shape[2]):\n",
    "        arrays.append(slices[i, :, k].reshape((-1, 1)))\n",
    "        indexes.append((i, k))\n",
    "df = pd.DataFrame(data=np.concatenate(arrays, axis=1), columns=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7680, 44536)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 0)</th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(0, 2)</th>\n",
       "      <th>(0, 3)</th>\n",
       "      <th>(0, 4)</th>\n",
       "      <th>(0, 5)</th>\n",
       "      <th>(0, 6)</th>\n",
       "      <th>(0, 7)</th>\n",
       "      <th>(0, 8)</th>\n",
       "      <th>(0, 9)</th>\n",
       "      <th>...</th>\n",
       "      <th>(3, 11124)</th>\n",
       "      <th>(3, 11125)</th>\n",
       "      <th>(3, 11126)</th>\n",
       "      <th>(3, 11127)</th>\n",
       "      <th>(3, 11128)</th>\n",
       "      <th>(3, 11129)</th>\n",
       "      <th>(3, 11130)</th>\n",
       "      <th>(3, 11131)</th>\n",
       "      <th>(3, 11132)</th>\n",
       "      <th>(3, 11133)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.768583</td>\n",
       "      <td>4.062278</td>\n",
       "      <td>0.068191</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.896838</td>\n",
       "      <td>1.270216</td>\n",
       "      <td>0.166997</td>\n",
       "      <td>0.279547</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.786159</td>\n",
       "      <td>3.978283</td>\n",
       "      <td>0.071347</td>\n",
       "      <td>0.185681</td>\n",
       "      <td>0.909932</td>\n",
       "      <td>1.251200</td>\n",
       "      <td>0.168637</td>\n",
       "      <td>0.283131</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.021285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.798708</td>\n",
       "      <td>3.928351</td>\n",
       "      <td>0.075165</td>\n",
       "      <td>0.182488</td>\n",
       "      <td>0.919788</td>\n",
       "      <td>1.239611</td>\n",
       "      <td>0.170250</td>\n",
       "      <td>0.283795</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>0.020410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.807307</td>\n",
       "      <td>3.837626</td>\n",
       "      <td>0.077927</td>\n",
       "      <td>0.183336</td>\n",
       "      <td>0.923947</td>\n",
       "      <td>1.236829</td>\n",
       "      <td>0.169759</td>\n",
       "      <td>0.289778</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>0.021586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.826311</td>\n",
       "      <td>3.953005</td>\n",
       "      <td>0.075382</td>\n",
       "      <td>0.180245</td>\n",
       "      <td>0.918134</td>\n",
       "      <td>1.298391</td>\n",
       "      <td>0.167393</td>\n",
       "      <td>0.291165</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     (0, 0)    (0, 1)    (0, 2)    (0, 3)    (0, 4)    (0, 5)    (0, 6)  \\\n",
       "0  3.768583  4.062278  0.068191  0.186343  0.896838  1.270216  0.166997   \n",
       "1  3.786159  3.978283  0.071347  0.185681  0.909932  1.251200  0.168637   \n",
       "2  3.798708  3.928351  0.075165  0.182488  0.919788  1.239611  0.170250   \n",
       "3  3.807307  3.837626  0.077927  0.183336  0.923947  1.236829  0.169759   \n",
       "4  3.826311  3.953005  0.075382  0.180245  0.918134  1.298391  0.167393   \n",
       "\n",
       "     (0, 7)    (0, 8)    (0, 9)  ...  (3, 11124)  (3, 11125)  (3, 11126)  \\\n",
       "0  0.279547  0.010298  0.021636  ...         0.0         0.0         0.0   \n",
       "1  0.283131  0.010680  0.021285  ...         0.0         0.0         0.0   \n",
       "2  0.283795  0.011001  0.020410  ...         0.0         0.0         0.0   \n",
       "3  0.289778  0.010817  0.021586  ...         0.0         0.0         0.0   \n",
       "4  0.291165  0.010460  0.021717  ...         0.0         0.0         0.0   \n",
       "\n",
       "   (3, 11127)  (3, 11128)  (3, 11129)  (3, 11130)  (3, 11131)  (3, 11132)  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   (3, 11133)  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 44536 columns]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_builder import get_pipeline_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persistence_entropy': I[0, 2),\n",
       " 'amplitude_bottleneck_inf': I[2, 4),\n",
       " 'amplitude_wasserstein_1': I[4, 6),\n",
       " 'amplitude_wasserstein_2': I[6, 8),\n",
       " 'amplitude_landscape_1_1_100': I[8, 10),\n",
       " 'amplitude_landscape_1_2_100': I[10, 12),\n",
       " 'amplitude_landscape_2_1_100': I[12, 14),\n",
       " 'amplitude_landscape_2_2_100': I[14, 16),\n",
       " 'amplitude_betti_1_100': I[16, 18),\n",
       " 'amplitude_betti_2_100': I[18, 20),\n",
       " 'amplitude_heat_1_1.6_100': I[20, 22),\n",
       " 'amplitude_heat_1_3.2_100': I[22, 24),\n",
       " 'amplitude_heat_2_1.6_100': I[24, 26),\n",
       " 'amplitude_heat_2_3.2_100': I[26, 28),\n",
       " 'derivative_bottleneck_inf': I[28, 30),\n",
       " 'derivative_wasserstein_1': I[30, 32),\n",
       " 'derivative_wasserstein_2': I[32, 34),\n",
       " 'heat_kernel_1.6': I[34, 5034),\n",
       " 'heat_kernel_3.2': I[5034, 10034),\n",
       " 'betti_curve': I[10034, 10134),\n",
       " 'pers_landscape': I[10134, 11134)}"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_transf = get_pipeline_index()\n",
    "dict_transf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features based on RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly defined the regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "sim_code_k = sim_code\n",
    "if sim_code.split('_')[-1] == 'comp':\n",
    "    sim_code_k = sim_code.split('_')[0]\n",
    "x = loadmat(f'/Users/diegofiori/Desktop/epfl/master_thesis/k_perp_end_{sim_code_k}.mat')\n",
    "y = x['k_quantities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([y[i, :, :] for i in range(y.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_ind = np.any(y>0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y[non_zero_ind, 0]\n",
    "y2 = y[non_zero_ind, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[non_zero_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "def compute_correlation_with_old_features(target_feat, old_features_idx, X):\n",
    "    corr = [pearsonr(target_feat, X[:, old_idx])[0] for old_idx in old_features_idx]\n",
    "    return np.abs(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976712a15075485f9b1256f3f2ca110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=44536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegofiori/anaconda3/envs/giotto_tda_env/lib/python3.8/site-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "# remove some features which are higly correlated\n",
    "X = np.nan_to_num(X)\n",
    "columns_idx = []\n",
    "columns_tuple_id = [(i, j) for i in range(slices.shape[0]) for j in range(slices.shape[2])]\n",
    "equi_class = {}\n",
    "class_id = 0\n",
    "for i in tqdm(range(X.shape[1])):  \n",
    "    feat_mat = X[:, i]\n",
    "    if columns_idx:\n",
    "        corrs = [compute_correlation_with_old_features(feat_mat, columns_idx, X)]\n",
    "        if np.max(corrs) < 0.95:\n",
    "            columns_idx.append(i)\n",
    "            equi_class[class_id] = [columns_tuple_id[i]]\n",
    "            class_id += 1\n",
    "        else:\n",
    "            equi_class[np.argmin(corrs)].append(columns_tuple_id[i])\n",
    "    else:\n",
    "        columns_idx.append(i)\n",
    "        equi_class[class_id] = [columns_tuple_id[i]]\n",
    "        class_id += 1\n",
    "X = X[:, np.array(columns_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equi_class = {equi_class[i][0]: equi_class[i] for i in equi_class.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y1_train, y1_test, y2_train, y2_test = train_test_split(X, y1, y2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n",
    "model1.fit(X_train, y1_train)\n",
    "model2 = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n",
    "model2.fit(X_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_1 = model1.score(X_test, y1_test)\n",
    "score_2 = model2.score(X_test, y2_test)\n",
    "total_score = score_1 + score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.predict(X_test[19:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y1_test, model1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('relative error')\n",
    "mean_absolute_error(y1_test, model1.predict(X_test))/np.mean(y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = score_1/total_score*model1.feature_importances_ + score_2/total_score*model2.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the features (we want to keep all the spatial dimensions)\n",
    "n_features = slices.shape[2]\n",
    "#feature_importance_temp = [feature_importance[i:i+n_features] for i in range(0, len(feature_importance), n_features)]\n",
    "#feature_importance_temp = [np.mean(feature_importance_temp[i:i+80], axis=0) \n",
    "#                           for i in range(0, len(feature_importance_temp), 80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_idx = [(i, j) for i in range(slices.shape[0])\n",
    "                          for j in range(n_features)]\n",
    "feature_importance_idx = [feature_importance_idx[i] for i in range(len(feature_importance_idx)) if i in columns_idx]\n",
    "feature_importance_idx_sort = sorted(feature_importance_idx, reverse=True,\n",
    "                                key=lambda x: feature_importance[feature_importance_idx.index(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_idx = []\n",
    "threshold = 0.85\n",
    "minimum_value = np.max(feature_importance)/100\n",
    "for i, idx in enumerate(tqdm(feature_importance_idx_sort)):\n",
    "    feat_value = feature_importance[feature_importance_idx.index(idx)]\n",
    "    if feat_value < minimum_value:\n",
    "        break\n",
    "    feat_mat = X[:, feature_importance_idx.index(idx)]\n",
    "    if important_features_idx:\n",
    "        corrs = [compute_correlation_with_old_features(feat_mat, important_features_idx, X)]\n",
    "        if np.max(corrs) < threshold:\n",
    "            important_features_idx.append(i)\n",
    "        else:\n",
    "            list_temp = equi_class.pop(idx)\n",
    "            equi_class[feature_importance_idx_sort[important_features_idx[np.argmax(corrs)]]] += list_temp\n",
    "    else:\n",
    "        important_features_idx.append(i)\n",
    "important_features = [feature_importance_idx_sort[i] for i in important_features_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_equi_class = {key: equi_class[key] for key in important_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import write_pickle\n",
    "write_pickle(path=path+f'selected_index_{sim_code}.pickle', array=important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(path=path+f'selected_equi_class_{sim_code}.pickle', array=important_equi_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis for equi_class and indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with and without the the 2 big components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_code = 'cs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equi_class_no_com = read_pickle(path=path+f'selected_equi_class_{sim_code}_no_comp.pickle')\n",
    "equi_class_norm = read_pickle(path=path+f'selected_equi_class_{sim_code}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_equi_classes(equi_1, equi_2):\n",
    "    common_eq_classes = {}\n",
    "    class_idx = 0\n",
    "    for key_1 in equi_1.keys():\n",
    "        set_temp_1 = set(equi_1[key_1])\n",
    "        for key_2 in equi_2.keys(): \n",
    "            set_res = set(equi_2[key_2]).intersection(set_temp_1)\n",
    "            if len(set_res) > 0:\n",
    "                common_eq_classes[class_idx] = list(set_res)\n",
    "                class_idx += 1\n",
    "    return common_eq_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_equi_classes(equi_1, equi_2):\n",
    "    union_eq_classes = {i: equi_2[key] for i, key in enumerate(equi_2.keys())}\n",
    "    class_idx = len(union_eq_classes)\n",
    "    for key_1 in equi_1.keys():\n",
    "        set_temp_1 = set(equi_1[key_1])\n",
    "        for key_2 in equi_2.keys(): \n",
    "            set_res = set(equi_2[key_2]).intersection(set_temp_1)\n",
    "            if len(set_res) == 0:\n",
    "                union_eq_classes[class_idx] = equi_1[key_1]\n",
    "                class_idx += 1\n",
    "                break\n",
    "    return union_eq_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_equi = intersect_equi_classes(equi_class_no_com, equi_class_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_equi = union_equi_classes(equi_class_no_com, equi_class_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(intersection_equi)/len(union_equi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs_index = read_pickle(path+f'selected_index_cs.pickle')\n",
    "sf_index = read_pickle(path+f'selected_index_sf.pickle')\n",
    "ds_index = read_pickle(path+f'selected_index_ds.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2185792349726776"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cs_index).intersection(set(sf_index)))/len(set(cs_index).union(set(sf_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cs_index).intersection(set(sf_index)).intersection(set(ds_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_selected_indices = list(set(cs_index).intersection(set(sf_index)).intersection(set(ds_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0), (2, 6), (3, 4)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sf_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0),\n",
       " (0, 10639),\n",
       " (0, 10185),\n",
       " (3, 11030),\n",
       " (2, 6494),\n",
       " (2, 10187),\n",
       " (2, 7),\n",
       " (3, 1),\n",
       " (1, 10385),\n",
       " (1, 4239)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 10639),\n",
       " (0, 10285),\n",
       " (0, 10235),\n",
       " (0, 10185),\n",
       " (2, 2968),\n",
       " (3, 10681),\n",
       " (3, 10224),\n",
       " (3, 2),\n",
       " (2, 2969),\n",
       " (3, 4)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persistence_entropy': I[0, 2),\n",
       " 'amplitude_bottleneck_inf': I[2, 4),\n",
       " 'amplitude_wasserstein_1': I[4, 6),\n",
       " 'amplitude_wasserstein_2': I[6, 8),\n",
       " 'amplitude_landscape_1_1_100': I[8, 10),\n",
       " 'amplitude_landscape_1_2_100': I[10, 12),\n",
       " 'amplitude_landscape_2_1_100': I[12, 14),\n",
       " 'amplitude_landscape_2_2_100': I[14, 16),\n",
       " 'amplitude_betti_1_100': I[16, 18),\n",
       " 'amplitude_betti_2_100': I[18, 20),\n",
       " 'amplitude_heat_1_1.6_100': I[20, 22),\n",
       " 'amplitude_heat_1_3.2_100': I[22, 24),\n",
       " 'amplitude_heat_2_1.6_100': I[24, 26),\n",
       " 'amplitude_heat_2_3.2_100': I[26, 28),\n",
       " 'derivative_bottleneck_inf': I[28, 30),\n",
       " 'derivative_wasserstein_1': I[30, 32),\n",
       " 'derivative_wasserstein_2': I[32, 34),\n",
       " 'heat_kernel_1.6': I[34, 5034),\n",
       " 'heat_kernel_3.2': I[5034, 10034),\n",
       " 'betti_curve': I[10034, 10134),\n",
       " 'pers_landscape': I[10134, 11134)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_transf = get_pipeline_index()\n",
    "dict_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_index_no_comp = read_pickle(path+f'selected_index_cs_no_comp.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 10637),\n",
       " (1, 10236),\n",
       " (1, 10385),\n",
       " (1, 10637),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 10186),\n",
       " (2, 10236),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 7),\n",
       " (3, 30),\n",
       " (3, 2287),\n",
       " (3, 10230),\n",
       " (3, 10231),\n",
       " (3, 10731),\n",
       " (3, 10830),\n",
       " (3, 10881),\n",
       " (3, 11131)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(cs_index_no_comp).intersection(cs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
